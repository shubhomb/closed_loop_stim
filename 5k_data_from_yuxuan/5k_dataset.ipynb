{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33871d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3396476, 2)\n",
      "47  unique neurons recorded\n",
      "328503.754  seconds of recording\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>neuron_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>246</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>340</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  neuron_id\n",
       "0        122        206\n",
       "1        196          5\n",
       "2        244        200\n",
       "3        246        300\n",
       "4        340        200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import pickle\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datadir = \"5k_data_from_yuxuan/\"\n",
    "\n",
    "# 5000 patterns. Each pattern consists of indices characterized by which chnanels are modulated oen of 4 delay modes. 44 stimulating channels are used (though some pattern indices have no stimulation on any channels). \n",
    "# Each stim is 3 uA amplitude, biphasic, 167-66-167 us biphasic pulses with 66 us interphase interval. \n",
    "# approx 30kHz sampling rate but imprecise.\n",
    "\n",
    "# Each stimulation is delivered in 600 ms period, with 1400 inter-stimulation interval. Thus, 0.2 s per stimulation * 5000 stimulations = 1000 seconds total experiment.\n",
    "\n",
    "pattern_registrations = pickle.load(open(os.path.join(datadir, \"pattern_registrations.pkl\"), \"rb\"))\n",
    "\n",
    "# spkVecs contains spike times for all neurons. 47 are recorded.\n",
    "spikes_df = pd.DataFrame(np.load(os.path.join(datadir, \"spkVecs.npy\"))) # size = (3396476,))\n",
    "spikes_df.columns = ['timestamp', 'neuron_id', 'segment_index']\n",
    "spikes_df.drop(columns=['segment_index'], inplace=True)\n",
    "spikes_df['timestamp'] = spikes_df['timestamp'].astype(int)\n",
    "spikes_df['neuron_id'] = spikes_df['neuron_id'].astype(int) # noncontinuous neuron ids from with numbers corresponding to shank location\n",
    "spikes_df.sort_values(by=['timestamp', 'neuron_id'], inplace=True)\n",
    "print (spikes_df.shape)\n",
    "print (spikes_df['neuron_id'].nunique(), \" unique neurons recorded\")\n",
    "print (spikes_df['timestamp'].max()/1000, \" seconds of recording\")\n",
    "spikes_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cb331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pattern timestamp: 328442242\n",
      "Max pattern timestamp: 905905\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_pattern_json(data):\n",
    "    # 1. Flatten the Pattern -> Steps level\n",
    "    # We use record_path to reach the 'steps' and meta to keep parent info\n",
    "    df = pd.json_normalize(\n",
    "        data, \n",
    "        record_path=['steps'], \n",
    "        meta=[\n",
    "            'pattern_name', # given name of the pattern\n",
    "            'pattern_lambda', # given lambda parameter that generated the pattern \n",
    "            'pattern_flag_start_timestamp', # given starting timpestamp of pattern\n",
    "            'pattern_timing_index' # given order of pattern from 1-5,000 (first to last)\n",
    "        ],\n",
    "        record_prefix='step_'\n",
    "    )\n",
    "    # 2. Flatten the 'step_channel_delays' list into individual rows\n",
    "    # This creates a row for every delay entry. Steps with [] will become NaN.\n",
    "    df = df.explode('step_channel_delays').reset_index(drop=True)\n",
    "\n",
    "    # 3. Convert the dictionaries in 'step_channel_delays' into separate columns\n",
    "    delays_df = pd.json_normalize(df['step_channel_delays'])\n",
    "    \n",
    "    # 4. Store pattern length\n",
    "    df['pattern_idx_length'] = df.groupby('pattern_timing_index')['step_index'].transform('max') + 1\n",
    "\n",
    "    # 6. Combine and cleanup\n",
    "    final_df = pd.concat([df.drop(columns=['step_channel_delays']), delays_df], axis=1)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Usage:\n",
    "pattern_df = read_pattern_json(pattern_registrations)\n",
    "pattern_df.head(30)\n",
    "max_pattern_timestamp = pattern_df['step_start_timestamp'].max()\n",
    "min_pattern_timestamp = pattern_df['step_start_timestamp'].min()\n",
    "print (f\"Min pattern timestamp: {min_pattern_timestamp}\")\n",
    "print (f\"Max pattern timestamp: {max_pattern_timestamp}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee0b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.608243e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.449670e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.232250e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.871570e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.589370e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.417233e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.284422e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           end_time\n",
       "count  5.000000e+03\n",
       "mean   1.608243e+08\n",
       "std    9.449670e+07\n",
       "min    9.232250e+05\n",
       "25%    7.871570e+07\n",
       "50%    1.589370e+08\n",
       "75%    2.417233e+08\n",
       "max    3.284422e+08"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_df['pattern_idx_length'].value_counts()\n",
    "\n",
    "# how many times each pattern appears in separate timestamps\n",
    "pattern_counts = pattern_df[['pattern_name', 'pattern_timing_index']].drop_duplicates().groupby('pattern_name').size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd6951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "000d9663",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_spike_raster(df, neurons=None, time_range=None, tick_height=0.8):\n",
    "    \"\"\"\n",
    "    Plots a spike raster plot from a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'timestamp' and 'neuron_id'\n",
    "    - neurons: List of neuron IDs to plot (None = all)\n",
    "    - time_range: Tuple of (min_time, max_time) to zoom in\n",
    "    - tick_height: Vertical scale of the spike marks\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Filter by Time Interval (if provided)\n",
    "    if time_range:\n",
    "        df = df[(df['timestamp'] >= time_range[0]) & (df['timestamp'] <= time_range[1])]\n",
    "    \n",
    "    # 2. Filter by Neuron IDs (if provided)\n",
    "    if neurons is not None:\n",
    "        df = df[df['neuron_id'].isin(neurons)]\n",
    "    \n",
    "    # 3. Group timestamps by neuron_id\n",
    "    # We create a list of arrays, where each array contains timestamps for one neuron\n",
    "    grouped = df.groupby('neuron_id')['timestamp'].apply(np.array)\n",
    "    \n",
    "    # Prepare data for eventplot\n",
    "    spike_data = grouped.values\n",
    "    neuron_labels = grouped.index.values\n",
    "\n",
    "    # 4. Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.eventplot(spike_data, lineoffsets=neuron_labels, linelengths=tick_height, color='black')\n",
    "\n",
    "    plt.title('Spike Raster Plot')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Neuron ID')\n",
    "    \n",
    "    # Set y-ticks to show specific neuron IDs clearly\n",
    "    plt.yticks(neuron_labels)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage:\n",
    "# Plot all neurons\n",
    "# plot_spike_raster(spkVecs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_per_stimulation_rasters(spkVecs, pattern_df, output_dir='rasters'):\n",
    "    \"\"\"\n",
    "    Creates a separate raster plot for every stimulation event in pattern_df.\n",
    "    \n",
    "    Parameters:\n",
    "    - spkVecs: DataFrame with spike ['timestamp', 'neuron_id']\n",
    "    - pattern_df: DataFrame with ['step_index', 'step_start_timestamp', 'pattern_name']\n",
    "    - output_dir: Directory to save the figures\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 1. Identify unique stimulation steps\n",
    "    # We group by step_index to get the start time of each pattern\n",
    "    patterns = pattern_df.groupby(['pattern_timing_index', 'pattern_name'])['pattern_flag_start_timestamp'].first().reset_index()\n",
    "    \n",
    "    # 2. Determine the end time for each step (start of the next step)\n",
    "    patterns['pattern_end_timestamp'] = patterns['pattern_flag_start_timestamp'].shift(-1)\n",
    "    \n",
    "    # Handle the very last pattern (which has no 'next' start time)\n",
    "    # We can add a fixed duration or use the last spike time\n",
    "    last_spike_time = spkVecs['timestamp'].max()\n",
    "    patterns['pattern_end_timestamp'] = patterns['pattern_end_timestamp'].fillna(last_spike_time)\n",
    "    y_positions = np.arange(len(spkVecs['neuron_id'].unique()))\n",
    "    y_labels = spkVecs['neuron_id'].unique()\n",
    "    # 3. Iterate through each stimulation and plot\n",
    "    for i, row in patterns.iterrows():\n",
    "        idx = int(row['pattern_timing_index'])\n",
    "        t_start = row['pattern_flag_start_timestamp']\n",
    "        t_end = row['pattern_end_timestamp']\n",
    "        name = row['pattern_name']\n",
    "        \n",
    "        # Filter spikes for this interval\n",
    "        mask = (spkVecs['timestamp'] >= t_start) & (spkVecs['timestamp'] < t_end)\n",
    "        interval_spikes = spkVecs[mask]\n",
    "        \n",
    "        if interval_spikes.empty:\n",
    "            print(f\"Skipping Pattern ({name}): No spikes found between {t_start} and {t_end}\")\n",
    "            continue\n",
    "\n",
    "        # Group data for eventplot\n",
    "        grouped = interval_spikes.groupby('neuron_id')['timestamp'].apply(np.array)\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # Use the marker '|' to simulate the vertical tick look\n",
    "        plt.scatter(pattern_df['timestamp'], pattern_df['neuron_id'], \n",
    "                    marker='|', color='black', s=100, linewidths=0.5)\n",
    "        \n",
    "        plt.title(f\"Pattern {name} | Time: {t_start/1000} to {t_end/1000} s\")\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel('Neuron ID')\n",
    "        plt.yticks(y_positions, y_labels)\n",
    "        plt.xlim(t_start, t_end) # Ensure the x-axis matches the pattern window\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Save figure\n",
    "        file_path = os.path.join(output_dir, f\"raster_pattern_{name}.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close() # Close to free up memory\n",
    "        \n",
    "    print(f\"Finished! {len(steps)} potential plots processed and saved to '{output_dir}'.\")\n",
    "\n",
    "# Run the function\n",
    "plot_per_stimulation_rasters(spkVecs, pattern_df, \"figures/patterns/rasters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b23653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
